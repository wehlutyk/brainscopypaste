{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Paper figure: evolution of the distribution of features throughout recursively filtered timebags"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Some loading and prep code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First some imports\n",
      "import numpy as np\n",
      "import matplotlib as mpl\n",
      "import seaborn as sb\n",
      "%matplotlib inline\n",
      "\n",
      "import settings as st\n",
      "import datainterface.picklesaver as ps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "included_features = ['aoa_Kuperman',\n",
      "                     'mt_frequencies',\n",
      "                     'fa_CCs',\n",
      "                     'cmu_MNphonemes',\n",
      "                     'wn_MNSyns']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Translating internal feature names to public names\n",
      "tr_map = {'aoa_Kuperman': 'Age of acquisition',\n",
      "          'cmu_MNphonemes': r'$\\left< \\right.$ \\# phonemes $\\left. \\right>$',\n",
      "          'cmu_MNsyllables': r'$\\left< \\right.$ \\# syllables $\\left. \\right>$',\n",
      "          'fa_BCs': 'FA log-betweenness',\n",
      "          'fa_CCs': 'FA log-clustering',\n",
      "          'fa_degrees': 'FA log-degree',\n",
      "          'fa_PR_scores': 'FA log-pagerank',\n",
      "          'mt_frequencies': 'Log-frequency',\n",
      "          'mt_start_frequencies': 'Log-frequency in start quotes',\n",
      "          'wn_BCs': 'WN log-betweenness',\n",
      "          'wn_CCs': 'WN log-clustering',\n",
      "          'wn_degrees': 'WN log-degree',\n",
      "          'wn_MNSyns': r'Log $\\left< \\right.$ \\# synonyms $\\left. \\right>$',\n",
      "          'wn_NSigns': r'Log \\# meanings',\n",
      "          'wn_PR_scores': 'WN log-pagerank'}\n",
      "\n",
      "def translate(labels):\n",
      "    \"\"\"Translate a list of internal labels to human-readable ones.\"\"\"\n",
      "    if isinstance(labels, list):\n",
      "        return [tr_map[l] for l in labels]\n",
      "    else:\n",
      "        return tr_map[labels]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "def build_nwords_string(nvalues):\n",
      "    \"\"\"Compute a string like '1K words' or '20M words' from 1,000 or 20,000,000.\"\"\"\n",
      "    n_power = np.floor(np.log10(nvalues))\n",
      "    n_basepower = 3 * int(n_power // 3)\n",
      "    bstring = '{} words' if n_basepower == 0 else ('$\\sim$ {} K words' if n_basepower == 3 else '$\\sim$ {} M words')\n",
      "    return bstring.format(int(np.round(nvalues / 10 ** n_basepower)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The analysis itself\n",
      "\n",
      "We want to look at the distribution of features in *new* quotes produced by susbtitution (i.e. not those reinjected from outside as part of the continuous process). So for each cluster, we look at the first timebag, and take it as a reference and include all quotes in the second timebag that aren't in the first but are at distance *d* from a quote in the first. We repeat this operation for each later timebag, but basing ourselves on the set of new quotes produced by the previous step. Then on each of these sets of quotes, we compute the distribution of features. This gives us the distribution of features on the novel quotes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "empirical_features = ps.load('data/analyses/empirical_features_recursive_min-20-tbgs_no-exclusion.pickle')\n",
      "np_new_quotes_counts = ps.load('data/analyses/new_quotes_counts_recursive_min-20-tbgs_no-exclusion.pickle')\n",
      "print 'Loaded from pickle.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loaded from pickle.\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plot the results\n",
      "\n",
      "We now plot the distribution of features for novel quotes, for each feature, for a number of timebags. And see if it evolves."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbins = 15             # Number of bins to use in histograms\n",
      "n_timebags_shown = 10  # Number of timebags to plot for each feature\n",
      "n_timebags_step = 2    # Step between two plotted timebags\n",
      "small_fontsize = 8     # fontsize for small, not so important text\n",
      "med_fontsize = 10      # fontsize for medium, moderately important text\n",
      "big_fontsize = 14      # fontsize for big, important text\n",
      "palette = sb.color_palette('husl', len(included_features))\n",
      "\n",
      "fig, axs = mpl.pyplot.subplots(len(included_features), n_timebags_shown,\n",
      "                               figsize=(1.8 * n_timebags_shown, 2 * len(included_features)),\n",
      "                               sharey='row')\n",
      "word_counts = np.zeros((len(included_features), n_timebags_shown))\n",
      "\n",
      "for i, ffullname in enumerate(included_features):\n",
      "    ffullname_parts = ffullname.split('_')\n",
      "    fsrc = ffullname_parts[0]\n",
      "    ftype = '_'.join(ffullname_parts[1:])\n",
      "    \n",
      "    log = st.mt_analysis_features[fsrc][ftype]['log']\n",
      "    tbgs_empirical_values = empirical_features[fsrc][ftype]\n",
      "    \n",
      "    vals = []\n",
      "    for lvals in tbgs_empirical_values[:n_timebags_shown * n_timebags_step:n_timebags_step]:\n",
      "        # Convert to log if asked to\n",
      "        vals.append(np.log(lvals) if log else lvals)\n",
      "    vmin = np.array([v.min() for v in vals]).min()\n",
      "    vmax = np.array([v.max() for v in vals]).max()\n",
      "    bins = np.linspace(vmin, vmax, nbins)\n",
      "    \n",
      "    axs[i, 0].set_ylabel(translate(ffullname), fontsize=big_fontsize)\n",
      "    for j in range(n_timebags_shown):\n",
      "        axs[i, j].hist(vals[j], bins=bins, log=log, normed=True, color=palette[i], alpha=0.5)\n",
      "        axs[i, j].set_xlim([bins.min(), bins.max()])\n",
      "        axs[i, j].set_xticklabels(axs[i, j].get_xticks(), rotation=60, fontsize=small_fontsize)\n",
      "        axs[i, j].set_yticklabels(axs[i, j].get_yticks(), fontsize=small_fontsize)\n",
      "        word_counts[i, j] = len(vals[j])\n",
      "\n",
      "for j in range(n_timebags_shown):\n",
      "    axs[0, j].set_xlabel('bag {}'.format(j * n_timebags_step), fontsize=big_fontsize)\n",
      "    axs[-1, j].set_xlabel('bag {}'.format(j * n_timebags_step), fontsize=big_fontsize)\n",
      "\n",
      "for i, ffullname in enumerate(included_features):\n",
      "    ffullname_parts = ffullname.split('_')\n",
      "    fsrc = ffullname_parts[0]\n",
      "    ftype = '_'.join(ffullname_parts[1:])\n",
      "    \n",
      "    log = st.mt_analysis_features[fsrc][ftype]['log']\n",
      "    for j in range(n_timebags_shown):\n",
      "        xmin, xmax = axs[i, j].get_xlim()\n",
      "        xspan = xmax - xmin\n",
      "        xpos = xmin + xspan * 0.95\n",
      "        ymin, ymax = axs[i, j].get_ylim()\n",
      "        if not log:\n",
      "            yspan = ymax - ymin\n",
      "            ypos = ymin + yspan * 0.95\n",
      "        else:\n",
      "            logyspan = np.log10(ymax) - np.log10(ymin)\n",
      "            ypos = 10 ** (np.log10(ymin) + logyspan * 0.95)\n",
      "        axs[i, j].text(xpos, ypos, build_nwords_string(word_counts[i, j]),\n",
      "                       ha='right', va='top', fontsize=med_fontsize,\n",
      "                       bbox=dict(facecolor=sb.desaturate('#EAEAF2', 0.2), alpha=0.7))\n",
      "\n",
      "fig.tight_layout()\n",
      "\n",
      "# Rescale lower rows compared to first one\n",
      "from matplotlib.transforms import Affine2D, TransformedBbox\n",
      "scaling = 0.95\n",
      "trans = Affine2D().scale(scaling).translate((1 - scaling) / 2, 0)\n",
      "for i in range(1, len(included_features)):\n",
      "    for j in range(n_timebags_shown):\n",
      "        bbox = axs[i, j].get_position()\n",
      "        axs[i, j].set_position(TransformedBbox(bbox, trans))\n",
      "# Add an arrow for time\n",
      "pts00 = axs[0, 0].get_position().get_points()\n",
      "pts01 = axs[0, 1].get_position().get_points()\n",
      "space_to_ax_width = (pts01[1, 0] - pts00[1, 0]) / (pts00[1, 0] - pts00[0, 0])\n",
      "xmin, xmax = axs[0, 0].get_xlim()\n",
      "x0 = xmin\n",
      "xwidth = (xmax - xmin) * space_to_ax_width * (n_timebags_shown - 1) + (xmax - xmin)\n",
      "ymin, ymax = axs[0, 0].get_ylim()\n",
      "ypos = ymin - 0.65 * (ymax - ymin)\n",
      "axs[0, 0].annotate('$t$', (x0, ypos), (x0 + xwidth, ypos),\n",
      "                   ha='right',\n",
      "                   arrowprops=dict(arrowstyle='<|-, head_length=.6, head_width=.3', color='#777777'),\n",
      "                   fontsize=big_fontsize * 1.2, annotation_clip=False)\n",
      "fig.savefig('paper-figures/timebags_evolution_recursive_min20_no-exclusion.png', bbox_inches='tight', dpi=300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    }
   ],
   "metadata": {}
  }
 ]
}